<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width">
  <title>Digital Forum</title>
  <link href="style.css" rel="stylesheet" type="text/css" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Pixelify+Sans:wght@400..700&family=VT323&display=swap" rel="stylesheet">
  <script src="script.js"></script>
</head>

<body onmouseover="redirect_to_cube()">

  <div class="maindiv">
    <div class="navigation"> 
      <a  href="index.html">Homepage</a>
      <a class="current" href="perspective1.html">Perspective: Training is Plagiarism</a>
      <a href="perspective2.html">Perspective: Training is fair use</a>
      <a href="cube.html">THE CUBE</a>
    </div>
    <h1> Generative AI is Unethical </h1>
    <p>In some people's opinions, LLMs like OpenAI's ChatGPT and Microsoft's Copilot use their training data in an unethical and possibly illegal way.
      OpenAI and Microsoft basically downloaded and scanned the entire internet to make their chatbots: that includes
       the contents of millions of copyrighted books, articles, and websites, among them the entire catalogue of the New York Times.
    </p>
    <p>   
        The Times is evidently not a fan of having all of their intellectual property fed to a machine, and <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">
        filed a lawsuit</a> against openAI in retaliation. <a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf">The lawsuit</a>
        argues that the New York Times' journalism is acutely dangerous and costly to produce, but Copilot and ChatGPT "free-ride" off of The Times' 
        efforts by simply using their articles "without permission or payment" in their training data. In The Times' opinion, it's especially unethical
        how these chatbots, built from their articles, are now <i>competing</i> with them.
    </p>

    <p>The New York Times is multi-billion dollar company with immense resources. But their lawsuit reflects the sentiment of independent creators who also
     feel wronged by AI companies. <a href="https://github.com/rspeer">Robyn Speer</a> is a programmer notable for several projects in the field of
     Natural Language Processing (NLP), which is basically the data science of words. Among these projects is <a href="https://github.com/rspeer/wordfreq"">wordfreq</a>", 
     a database of word frequencies in many languages, which Speer discontinued because of generative AI's profound effect on the internet:
     "The world where I had a reasonable way to collect reliable word frequencies is not the world we live in now", she writes in the project's README.md file,
     linking to <a href="https://github.com/rspeer/wordfreq/blob/master/SUNSET.md">SUNSET.md</a> where she describes in detail her grievances with LLMs. 
     
     <p> Speer, like the New York Times, believes that AI companies infringe on the copyrights of creators: she colorfully calls AI chatbots 
      "plagiarism machines" which "claim your words as [their] own". In the context of wordfreq, Speer laments how AI-generated text is now so common on the internet that
      the internet isn't a useful corpus for natural language anymore. She describes how AI doesn't write like people do: the word "delve", for example,
     increased in frequency by an order of magnitude after ChatGPT released, evidently because ChatGPT just uses it way more than the average human. Even if the internet 
     was still a reliable source of word frequencies, she argues, people are now very defensive against text-scraping tools because they assume they will be used to build
     AI models rather than for a "reasonable" purpose like counting the frequency of words.
    </p>
  </div>
      <script src="script.js"></script>
</body>

</html>
